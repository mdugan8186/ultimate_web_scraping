# ==== parsing price ====
import requests as r
from bs4 import BeautifulSoup


def get_price_information(ticker, exchange):
    url = f'https://www.google.com/finance/quote/{ticker}:{exchange}'
    resp = r.get(url)
    soup = BeautifulSoup(resp.content, 'html.parser')

    price_div = soup.find('div', attrs={'data-last-price': True})
    price = float(price_div['data-last-price'])
    currency = price_div['data-currency-code']

    return {
        'ticker': ticker,
        'exchange': exchange,
        'price': price,
        'currency': currency
    }


# if __name__ == '__main__':
#     print(get_price_information('MSFT', 'NASDAQ').prettify())

if __name__ == '__main__':
    print(get_price_information('MSFT', 'NASDAQ'))
    print(get_price_information('AMZN', 'NASDAQ'))


#
#
"""
== Setup ==
- Created a new project directory with a Python file: `main.py`
- Activated a virtual environment:
    - On macOS/Linux: `source venv/bin/activate`
    - On Windows: `venv\\Scripts\\activate.bat`
- Installed dependencies:
    - `requests==2.28.0`
    - `beautifulsoup4==4.11.2`
- Opened the project in PyCharm where the virtual environment is auto-activated in terminal
"""

# == Why Use a Virtual Environment? ==
"""
- Keeps dependencies isolated to this project
- Prevents version conflicts with other Python projects
- Good practice, though optional
"""

# == Target: Google Finance Ticker Page ==
"""
- Goal is to parse **price** and **currency** from a stock ticker's page
- Example: Google/Alphabet (GOOG)
    - URL format: `https://www.google.com/finance/quote/<TICKER>:<EXCHANGE>`
    - e.g., `https://www.google.com/finance/quote/MSFT:NASDAQ`
"""

# == Scraping Strategy ==
"""
- Use `requests.get(url)` to fetch the HTML
- Use `BeautifulSoup` to parse it: `soup = BeautifulSoup(html, "html.parser")`
- The stock price is nested inside a div with the attribute `data-last-price`
- Instead of relying on class names (which are unstable), we:
    - Search for a `div` with attribute `data-last-price`
    - Optionally also extract `data-currency-code`

Why?
- Class names are auto-generated by Google and change frequently
- HTML structure is fragile; relying on attributes like `data-last-price` is more robust
"""

# == Parsing Implementation Overview ==
"""
1. Construct the URL with an f-string using ticker and exchange
2. Fetch HTML using `requests.get(url)`
3. Parse HTML using `BeautifulSoup(html, "html.parser")`
4. Use `soup.find("div", attrs={"data-last-price": True})` to locate the price container
5. Extract:
    - `data-last-price`: the price (cast to `float`)
    - `data-currency-code`: the currency (as `str`)
6. Return a dictionary:
    ```python
    {
        "ticker": ...,
        "exchange": ...,
        "price": ...,
        "currency": ...
    }
    ```
"""

# == Example Output ==
"""
For MSFT on NASDAQ:
{
    'ticker': 'MSFT',
    'exchange': 'NASDAQ',
    'price': 421.44,
    'currency': 'USD'
}
"""

# == Testing ==
"""
- Use a conditional `if __name__ == "__main__"` block to run the function directly
- Call with:
    `get_price_info("MSFT", "NASDAQ")`
    `get_price_info("AMZN", "NASDAQ")`

- Used `print()` and `pprint()` to verify output formatting
"""

# == Notes on Parsers ==
"""
- BeautifulSoup warns if parser is not specified:
    - `html.parser` is the default
    - Others like `lxml` or `xml` are faster but require installation
"""
